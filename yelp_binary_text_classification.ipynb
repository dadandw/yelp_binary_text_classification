{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yelp_binary_text_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abZT3Lyq7Nbq"
      },
      "source": [
        "# Binary Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdSOsnohhAJZ",
        "outputId": "8971534b-e1d1-4278-dee2-30ce859417d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ3zFvQL7UWy"
      },
      "source": [
        "Untuk latihan kali ini kita akan menggunakan dataset Yelp yang berisi review dari beberapa restoran di Amerika Serikat. Dataset terdiri dari 2 kelas yaitu 0 dan 1 yang menunjukkan apakah review tersebut positif atau negatif. Dataset dapat diunduh pada [tautan](https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set?) ini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qaFvvXh7jBJ"
      },
      "source": [
        "## Load Dataset\n",
        "Setelah dataset diunduh, kita load dataset pada Colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93yjTLN3NJM"
      },
      "source": [
        "    import pandas as pd\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dicoding/dataset/sentiment labelled sentences/yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x2EzYdGr7z5a",
        "outputId": "1e5de909-3a6d-4161-902a-b8fa625d0764"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  label\n",
              "995  I think food should have flavor and texture an...      0\n",
              "996                           Appetite instantly gone.      0\n",
              "997  Overall I was not impressed and would not go b...      0\n",
              "998  The whole experience was underwhelming, and I ...      0\n",
              "999  Then, as if I hadn't wasted enough of my life ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKiry-gC7-TU"
      },
      "source": [
        "## Split Dataset\n",
        "Setelah itu kita bagi dataset menjadi train dan test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDhqTR-h75Gd"
      },
      "source": [
        "    from sklearn.model_selection import train_test_split\n",
        "    kalimat = df['sentence'].values\n",
        "    y = df['label'].values\n",
        "    kalimat_latih, kalimat_test, y_latih, y_test = train_test_split(kalimat, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iem5bXaS8Keu"
      },
      "source": [
        "## Tokenizer\n",
        "Agar teks dapat dipahami oleh model, kita harus lakukan tokenisasi. Gunakan fungsi tokenizer pada data latih dan data test. Jangan lupa gunakan fungsi pad_sequences agar setiap sequence sama panjang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGfdrIqB8FYE"
      },
      "source": [
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "     \n",
        "    tokenizer = Tokenizer(num_words=250, oov_token='x')\n",
        "    tokenizer.fit_on_texts(kalimat_latih) \n",
        "    tokenizer.fit_on_texts(kalimat_test)\n",
        "     \n",
        "    sekuens_latih = tokenizer.texts_to_sequences(kalimat_latih)\n",
        "    sekuens_test = tokenizer.texts_to_sequences(kalimat_test)\n",
        "     \n",
        "    padded_latih = pad_sequences(sekuens_latih) \n",
        "    padded_test = pad_sequences(sekuens_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lggLGVyE8Z_A"
      },
      "source": [
        "## Embedding\n",
        "Untuk arsitektur yang akan digunakan adalah layer embedding, dengan argumen pertama sesuai dengan jumlah vocabulary/kata yang kita pakai pada tokenizer. Argumen selanjutnya adalah dimensi embedding, dan input_length yang merupakan panjang dari sequence. Nah di kita tidak menggunakan layer Flatten melainkan kita menggantinya dengan GlobalAveragePooling1D. Fungsi ini bekerja lebih baik pada kasus NLP dibanding Flatten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuP2Xj_K8Sd4"
      },
      "source": [
        "    import tensorflow as tf\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(250, 16, input_length=20),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03KhjFnw8ozF"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJYonwk8zWO"
      },
      "source": [
        "Setelah arsitektur model dibentuk, dan loss function serta optimizer ditentukan, kita dapat memulai pelatihan model kita. Di sini penulis menggunakan 30 epoch. Anda bebas bereksperimen dengan nilai yang lain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrnXxOW58jzt",
        "outputId": "53b66041-a4ba-415d-a405-3cf7c940002a"
      },
      "source": [
        "    num_epochs = 30\n",
        "    history = model.fit(padded_latih, y_latih, epochs=num_epochs, \n",
        "                        validation_data=(padded_test, y_test), verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (32, 32).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (32, 32).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 29).\n",
            "25/25 - 3s - loss: 0.6930 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5700\n",
            "Epoch 2/30\n",
            "25/25 - 0s - loss: 0.6918 - accuracy: 0.5987 - val_loss: 0.6911 - val_accuracy: 0.6250\n",
            "Epoch 3/30\n",
            "25/25 - 0s - loss: 0.6902 - accuracy: 0.5975 - val_loss: 0.6891 - val_accuracy: 0.6350\n",
            "Epoch 4/30\n",
            "25/25 - 0s - loss: 0.6869 - accuracy: 0.6012 - val_loss: 0.6849 - val_accuracy: 0.5950\n",
            "Epoch 5/30\n",
            "25/25 - 0s - loss: 0.6816 - accuracy: 0.6275 - val_loss: 0.6802 - val_accuracy: 0.6350\n",
            "Epoch 6/30\n",
            "25/25 - 0s - loss: 0.6751 - accuracy: 0.6750 - val_loss: 0.6729 - val_accuracy: 0.5950\n",
            "Epoch 7/30\n",
            "25/25 - 0s - loss: 0.6654 - accuracy: 0.6587 - val_loss: 0.6638 - val_accuracy: 0.6300\n",
            "Epoch 8/30\n",
            "25/25 - 0s - loss: 0.6509 - accuracy: 0.7237 - val_loss: 0.6506 - val_accuracy: 0.6400\n",
            "Epoch 9/30\n",
            "25/25 - 0s - loss: 0.6310 - accuracy: 0.7075 - val_loss: 0.6362 - val_accuracy: 0.6900\n",
            "Epoch 10/30\n",
            "25/25 - 0s - loss: 0.6110 - accuracy: 0.7450 - val_loss: 0.6158 - val_accuracy: 0.6600\n",
            "Epoch 11/30\n",
            "25/25 - 0s - loss: 0.5813 - accuracy: 0.7638 - val_loss: 0.5984 - val_accuracy: 0.7100\n",
            "Epoch 12/30\n",
            "25/25 - 0s - loss: 0.5542 - accuracy: 0.7738 - val_loss: 0.5764 - val_accuracy: 0.7000\n",
            "Epoch 13/30\n",
            "25/25 - 0s - loss: 0.5246 - accuracy: 0.7950 - val_loss: 0.5598 - val_accuracy: 0.7200\n",
            "Epoch 14/30\n",
            "25/25 - 0s - loss: 0.4985 - accuracy: 0.8188 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "25/25 - 0s - loss: 0.4737 - accuracy: 0.8188 - val_loss: 0.5302 - val_accuracy: 0.7350\n",
            "Epoch 16/30\n",
            "25/25 - 0s - loss: 0.4506 - accuracy: 0.8325 - val_loss: 0.5162 - val_accuracy: 0.7400\n",
            "Epoch 17/30\n",
            "25/25 - 0s - loss: 0.4314 - accuracy: 0.8313 - val_loss: 0.5080 - val_accuracy: 0.7350\n",
            "Epoch 18/30\n",
            "25/25 - 0s - loss: 0.4125 - accuracy: 0.8425 - val_loss: 0.4953 - val_accuracy: 0.7600\n",
            "Epoch 19/30\n",
            "25/25 - 0s - loss: 0.3934 - accuracy: 0.8487 - val_loss: 0.4938 - val_accuracy: 0.7350\n",
            "Epoch 20/30\n",
            "25/25 - 0s - loss: 0.3801 - accuracy: 0.8562 - val_loss: 0.4907 - val_accuracy: 0.7350\n",
            "Epoch 21/30\n",
            "25/25 - 0s - loss: 0.3679 - accuracy: 0.8662 - val_loss: 0.4882 - val_accuracy: 0.7400\n",
            "Epoch 22/30\n",
            "25/25 - 0s - loss: 0.3534 - accuracy: 0.8637 - val_loss: 0.4805 - val_accuracy: 0.7600\n",
            "Epoch 23/30\n",
            "25/25 - 0s - loss: 0.3457 - accuracy: 0.8662 - val_loss: 0.4799 - val_accuracy: 0.7650\n",
            "Epoch 24/30\n",
            "25/25 - 0s - loss: 0.3400 - accuracy: 0.8637 - val_loss: 0.4824 - val_accuracy: 0.7700\n",
            "Epoch 25/30\n",
            "25/25 - 0s - loss: 0.3306 - accuracy: 0.8650 - val_loss: 0.4986 - val_accuracy: 0.7550\n",
            "Epoch 26/30\n",
            "25/25 - 0s - loss: 0.3196 - accuracy: 0.8850 - val_loss: 0.4940 - val_accuracy: 0.7600\n",
            "Epoch 27/30\n",
            "25/25 - 0s - loss: 0.3118 - accuracy: 0.8825 - val_loss: 0.4894 - val_accuracy: 0.7650\n",
            "Epoch 28/30\n",
            "25/25 - 0s - loss: 0.3027 - accuracy: 0.8913 - val_loss: 0.4982 - val_accuracy: 0.7550\n",
            "Epoch 29/30\n",
            "25/25 - 0s - loss: 0.2983 - accuracy: 0.8913 - val_loss: 0.4987 - val_accuracy: 0.7650\n",
            "Epoch 30/30\n",
            "25/25 - 0s - loss: 0.2927 - accuracy: 0.8975 - val_loss: 0.5042 - val_accuracy: 0.7700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ifls8F8_so"
      },
      "source": [
        "Hasil dari pelatihan model kita menunjukkan akurasi yang cukup baik dengan data yang sangat sedikit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxZYfhWe83ye"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}